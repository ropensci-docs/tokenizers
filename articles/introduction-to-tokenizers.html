<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="tokenizers">
<title>Introduction to the tokenizers Package â€¢ tokenizers</title>
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="/apple-touch-icon.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://docs.ropensci.org/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Introduction to the tokenizers Package">
<meta property="og:description" content="tokenizers">
<meta property="og:image" content="https://docs.ropensci.org/tokenizers/logo.png">
<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Matomo --><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/cookieconsent@3/build/cookieconsent.min.css">
<script src="https://cdn.jsdelivr.net/npm/cookieconsent@3/build/cookieconsent.min.js" data-cfasync="false"></script><script src="https://ropensci.org/scripts/matomo.js"></script><noscript><p><img src="https://ropensci.matomo.cloud/matomo.php?idsite=1&amp;rec=1" style="border:0;" alt=""></p></noscript>
<!-- End Matomo Code -->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    <a href="https://ropensci.org" class="external-link"><img src="https://ropensci.org/img/icon_short_white.svg" id="hexlogo" alt="rOpenSci"></a>
    <a class="navbar-brand me-2" href="../index.html">tokenizers</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">0.3.1</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"></ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/introduction-to-tokenizers.html">Introduction to the tokenizers Package</a>
    <a class="dropdown-item" href="../articles/tif-and-tokenizers.html">The Text Interchange Formats and the tokenizers Package</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/ropensci/tokenizers/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Introduction to the tokenizers Package</h1>
                        <h4 data-toc-skip class="author">Lincoln Mullen</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/ropensci/tokenizers/blob/HEAD/vignettes/introduction-to-tokenizers.Rmd" class="external-link"><code>vignettes/introduction-to-tokenizers.Rmd</code></a></small>
      <div class="d-none name"><code>introduction-to-tokenizers.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="package-overview">Package overview<a class="anchor" aria-label="anchor" href="#package-overview"></a>
</h2>
<p>In natural language processing, tokenization is the process of breaking human-readable text into machine readable components. The most obvious way to tokenize a text is to split the text into words. But there are many other ways to tokenize a text, the most useful of which are provided by this package.</p>
<p>The tokenizers in this package have a consistent interface. They all take either a character vector of any length, or a list where each element is a character vector of length one. The idea is that each element comprises a text. Then each function returns a list with the same length as the input vector, where each element in the list contains the tokens generated by the function. If the input character vector or list is named, then the names are preserved, so that the names can serve as identifiers.</p>
<p>Using the following sample text, the rest of this vignette demonstrates the different kinds of tokenizers in this package.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://docs.ropensci.org/tokenizers/">tokenizers</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span>max.print <span class="op">=</span> <span class="fl">25</span><span class="op">)</span></span>
<span></span>
<span><span class="va">james</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span></span>
<span>  <span class="st">"The question thus becomes a verbal one\n"</span>,</span>
<span>  <span class="st">"again; and our knowledge of all these early stages of thought and feeling\n"</span>,</span>
<span>  <span class="st">"is in any case so conjectural and imperfect that farther discussion would\n"</span>,</span>
<span>  <span class="st">"not be worth while.\n"</span>,</span>
<span>  <span class="st">"\n"</span>,</span>
<span>  <span class="st">"Religion, therefore, as I now ask you arbitrarily to take it, shall mean\n"</span>,</span>
<span>  <span class="st">"for us _the feelings, acts, and experiences of individual men in their\n"</span>,</span>
<span>  <span class="st">"solitude, so far as they apprehend themselves to stand in relation to\n"</span>,</span>
<span>  <span class="st">"whatever they may consider the divine_. Since the relation may be either\n"</span>,</span>
<span>  <span class="st">"moral, physical, or ritual, it is evident that out of religion in the\n"</span>,</span>
<span>  <span class="st">"sense in which we take it, theologies, philosophies, and ecclesiastical\n"</span>,</span>
<span>  <span class="st">"organizations may secondarily grow.\n"</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="character-and-character-shingle-tokenizers">Character and character-shingle tokenizers<a class="anchor" aria-label="anchor" href="#character-and-character-shingle-tokenizers"></a>
</h2>
<p>The character tokenizer splits texts into individual characters.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/basic-tokenizers.html">tokenize_characters</a></span><span class="op">(</span><span class="va">james</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span> </span>
<span><span class="co">#&gt;  [1] "t" "h" "e" "q" "u" "e" "s" "t" "i" "o" "n" "t" "h" "u" "s" "b" "e" "c" "o"</span></span>
<span><span class="co">#&gt; [20] "m" "e" "s" "a" "v" "e"</span></span>
<span><span class="co">#&gt;  [ reached getOption("max.print") -- omitted 517 entries ]</span></span></code></pre></div>
<p>You can also tokenize into character-based shingles.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/shingle-tokenizers.html">tokenize_character_shingles</a></span><span class="op">(</span><span class="va">james</span>, n <span class="op">=</span> <span class="fl">3</span>, n_min <span class="op">=</span> <span class="fl">3</span>, </span>
<span>                            strip_non_alphanum <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">20</span><span class="op">]</span></span>
<span><span class="co">#&gt;  [1] "the" "he " "e q" " qu" "que" "ues" "est" "sti" "tio" "ion" "on " "n t"</span></span>
<span><span class="co">#&gt; [13] " th" "thu" "hus" "us " "s b" " be" "bec" "eco"</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="word-and-word-stem-tokenizers">Word and word-stem tokenizers<a class="anchor" aria-label="anchor" href="#word-and-word-stem-tokenizers"></a>
</h2>
<p>The word tokenizer splits texts into words.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/basic-tokenizers.html">tokenize_words</a></span><span class="op">(</span><span class="va">james</span><span class="op">)</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt;  [1] "the"       "question"  "thus"      "becomes"   "a"         "verbal"   </span></span>
<span><span class="co">#&gt;  [7] "one"       "again"     "and"       "our"       "knowledge" "of"       </span></span>
<span><span class="co">#&gt; [13] "all"       "these"     "early"     "stages"    "of"        "thought"  </span></span>
<span><span class="co">#&gt; [19] "and"       "feeling"   "is"        "in"        "any"       "case"     </span></span>
<span><span class="co">#&gt; [25] "so"       </span></span>
<span><span class="co">#&gt;  [ reached getOption("max.print") -- omitted 87 entries ]</span></span></code></pre></div>
<p>Word stemming is provided by the <a href="https://cran.r-project.org/package=SnowballC" class="external-link">SnowballC</a> package.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/stem-tokenizers.html">tokenize_word_stems</a></span><span class="op">(</span><span class="va">james</span><span class="op">)</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt;  [1] "the"      "question" "thus"     "becom"    "a"        "verbal"  </span></span>
<span><span class="co">#&gt;  [7] "one"      "again"    "and"      "our"      "knowledg" "of"      </span></span>
<span><span class="co">#&gt; [13] "all"      "these"    "earli"    "stage"    "of"       "thought" </span></span>
<span><span class="co">#&gt; [19] "and"      "feel"     "is"       "in"       "ani"      "case"    </span></span>
<span><span class="co">#&gt; [25] "so"      </span></span>
<span><span class="co">#&gt;  [ reached getOption("max.print") -- omitted 87 entries ]</span></span></code></pre></div>
<p>You can also provide a vector of stopwords which will be omitted. The <a href="https://github.com/quanteda/stopwords" class="external-link">stopwords package</a>, which contains stopwords for many languages from several sources, is recommended. This argument also works with the n-gram and skip n-gram tokenizers.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/quanteda/stopwords" class="external-link">stopwords</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/basic-tokenizers.html">tokenize_words</a></span><span class="op">(</span><span class="va">james</span>, stopwords <span class="op">=</span> <span class="fu">stopwords</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/stopwords/man/stopwords.html" class="external-link">stopwords</a></span><span class="op">(</span><span class="st">"en"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt;  [1] "question"    "thus"        "becomes"     "verbal"      "one"        </span></span>
<span><span class="co">#&gt;  [6] "knowledge"   "early"       "stages"      "thought"     "feeling"    </span></span>
<span><span class="co">#&gt; [11] "case"        "conjectural" "imperfect"   "farther"     "discussion" </span></span>
<span><span class="co">#&gt; [16] "worth"       "religion"    "therefore"   "now"         "ask"        </span></span>
<span><span class="co">#&gt; [21] "arbitrarily" "take"        "shall"       "mean"        "us"         </span></span>
<span><span class="co">#&gt;  [ reached getOption("max.print") -- omitted 33 entries ]</span></span></code></pre></div>
<p>An alternative word stemmer often used in NLP that preserves punctuation and separates common English contractions is the Penn Treebank tokenizer.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/ptb-tokenizer.html">tokenize_ptb</a></span><span class="op">(</span><span class="va">james</span><span class="op">)</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt;  [1] "The"       "question"  "thus"      "becomes"   "a"         "verbal"   </span></span>
<span><span class="co">#&gt;  [7] "one"       "again"     ";"         "and"       "our"       "knowledge"</span></span>
<span><span class="co">#&gt; [13] "of"        "all"       "these"     "early"     "stages"    "of"       </span></span>
<span><span class="co">#&gt; [19] "thought"   "and"       "feeling"   "is"        "in"        "any"      </span></span>
<span><span class="co">#&gt; [25] "case"     </span></span>
<span><span class="co">#&gt;  [ reached getOption("max.print") -- omitted 101 entries ]</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="n-gram-and-skip-n-gram-tokenizers">N-gram and skip n-gram tokenizers<a class="anchor" aria-label="anchor" href="#n-gram-and-skip-n-gram-tokenizers"></a>
</h2>
<p>An n-gram is a contiguous sequence of words containing at least <code>n_min</code> words and at most <code>n</code> words. This function will generate all such combinations of n-grams, omitting stopwords if desired.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/ngram-tokenizers.html">tokenize_ngrams</a></span><span class="op">(</span><span class="va">james</span>, n <span class="op">=</span> <span class="fl">5</span>, n_min <span class="op">=</span> <span class="fl">2</span>,</span>
<span>                stopwords <span class="op">=</span> <span class="fu">stopwords</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/stopwords/man/stopwords.html" class="external-link">stopwords</a></span><span class="op">(</span><span class="st">"en"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt;  [1] "question thus"                         </span></span>
<span><span class="co">#&gt;  [2] "question thus becomes"                 </span></span>
<span><span class="co">#&gt;  [3] "question thus becomes verbal"          </span></span>
<span><span class="co">#&gt;  [4] "question thus becomes verbal one"      </span></span>
<span><span class="co">#&gt;  [5] "thus becomes"                          </span></span>
<span><span class="co">#&gt;  [6] "thus becomes verbal"                   </span></span>
<span><span class="co">#&gt;  [7] "thus becomes verbal one"               </span></span>
<span><span class="co">#&gt;  [8] "thus becomes verbal one knowledge"     </span></span>
<span><span class="co">#&gt;  [9] "becomes verbal"                        </span></span>
<span><span class="co">#&gt; [10] "becomes verbal one"                    </span></span>
<span><span class="co">#&gt; [11] "becomes verbal one knowledge"          </span></span>
<span><span class="co">#&gt; [12] "becomes verbal one knowledge early"    </span></span>
<span><span class="co">#&gt; [13] "verbal one"                            </span></span>
<span><span class="co">#&gt; [14] "verbal one knowledge"                  </span></span>
<span><span class="co">#&gt; [15] "verbal one knowledge early"            </span></span>
<span><span class="co">#&gt; [16] "verbal one knowledge early stages"     </span></span>
<span><span class="co">#&gt; [17] "one knowledge"                         </span></span>
<span><span class="co">#&gt; [18] "one knowledge early"                   </span></span>
<span><span class="co">#&gt; [19] "one knowledge early stages"            </span></span>
<span><span class="co">#&gt; [20] "one knowledge early stages thought"    </span></span>
<span><span class="co">#&gt; [21] "knowledge early"                       </span></span>
<span><span class="co">#&gt; [22] "knowledge early stages"                </span></span>
<span><span class="co">#&gt; [23] "knowledge early stages thought"        </span></span>
<span><span class="co">#&gt; [24] "knowledge early stages thought feeling"</span></span>
<span><span class="co">#&gt; [25] "early stages"                          </span></span>
<span><span class="co">#&gt;  [ reached getOption("max.print") -- omitted 197 entries ]</span></span></code></pre></div>
<p>A skip n-gram is like an n-gram in that it takes the <code>n</code> and <code>n_min</code> parameters. But rather than returning contiguous sequences of words, it will also return sequences of n-grams skipping words with gaps between <code>0</code> and the value of <code>k</code>. This function generates all such sequences, again omitting stopwords if desired. Note that the number of tokens returned can be very large.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/ngram-tokenizers.html">tokenize_skip_ngrams</a></span><span class="op">(</span><span class="va">james</span>, n <span class="op">=</span> <span class="fl">5</span>, n_min <span class="op">=</span> <span class="fl">2</span>, k <span class="op">=</span> <span class="fl">2</span>,</span>
<span>                     stopwords <span class="op">=</span> <span class="fu">stopwords</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/stopwords/man/stopwords.html" class="external-link">stopwords</a></span><span class="op">(</span><span class="st">"en"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt;  [1] "question thus"                     "question becomes"                 </span></span>
<span><span class="co">#&gt;  [3] "question verbal"                   "question thus becomes"            </span></span>
<span><span class="co">#&gt;  [5] "question thus verbal"              "question thus one"                </span></span>
<span><span class="co">#&gt;  [7] "question becomes verbal"           "question becomes one"             </span></span>
<span><span class="co">#&gt;  [9] "question becomes knowledge"        "question verbal one"              </span></span>
<span><span class="co">#&gt; [11] "question verbal knowledge"         "question verbal early"            </span></span>
<span><span class="co">#&gt; [13] "question thus becomes verbal"      "question thus becomes one"        </span></span>
<span><span class="co">#&gt; [15] "question thus becomes knowledge"   "question thus verbal one"         </span></span>
<span><span class="co">#&gt; [17] "question thus verbal knowledge"    "question thus verbal early"       </span></span>
<span><span class="co">#&gt; [19] "question thus one knowledge"       "question thus one early"          </span></span>
<span><span class="co">#&gt; [21] "question thus one stages"          "question becomes verbal one"      </span></span>
<span><span class="co">#&gt; [23] "question becomes verbal knowledge" "question becomes verbal early"    </span></span>
<span><span class="co">#&gt; [25] "question becomes one knowledge"   </span></span>
<span><span class="co">#&gt;  [ reached getOption("max.print") -- omitted 6083 entries ]</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="sentence-and-paragraph-tokenizers">Sentence and paragraph tokenizers<a class="anchor" aria-label="anchor" href="#sentence-and-paragraph-tokenizers"></a>
</h2>
<p>Sometimes it is desirable to split texts into sentences or paragraphs prior to tokenizing into other forms.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/basic-tokenizers.html">tokenize_sentences</a></span><span class="op">(</span><span class="va">james</span><span class="op">)</span> </span></code></pre></div>
<pre><code><span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [1] "The question thus becomes a verbal one again; and our knowledge of all these early stages of thought and feeling is in any case so conjectural and imperfect that farther discussion would not be worth while."                                               </span></span>
<span><span class="co">#&gt; [2] "Religion, therefore, as I now ask you arbitrarily to take it, shall mean for us _the feelings, acts, and experiences of individual men in their solitude, so far as they apprehend themselves to stand in relation to whatever they may consider the divine_."</span></span>
<span><span class="co">#&gt; [3] "Since the relation may be either moral, physical, or ritual, it is evident that out of religion in the sense in which we take it, theologies, philosophies, and ecclesiastical organizations may secondarily grow."</span></span></code></pre>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/basic-tokenizers.html">tokenize_paragraphs</a></span><span class="op">(</span><span class="va">james</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [1] "The question thus becomes a verbal one again; and our knowledge of all these early stages of thought and feeling is in any case so conjectural and imperfect that farther discussion would not be worth while."                                                                                                                                                                                                                                                                   </span></span>
<span><span class="co">#&gt; [2] "Religion, therefore, as I now ask you arbitrarily to take it, shall mean for us _the feelings, acts, and experiences of individual men in their solitude, so far as they apprehend themselves to stand in relation to whatever they may consider the divine_. Since the relation may be either moral, physical, or ritual, it is evident that out of religion in the sense in which we take it, theologies, philosophies, and ecclesiastical organizations may secondarily grow. "</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="text-chunking">Text chunking<a class="anchor" aria-label="anchor" href="#text-chunking"></a>
</h2>
<p>When one has a very long document, sometimes it is desirable to split the document into smaller chunks, each with the same length. This function chunks a document and gives it each of the chunks an ID to show their order. These chunks can then be further tokenized.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">chunks</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/chunk_text.html">chunk_text</a></span><span class="op">(</span><span class="va">mobydick</span>, chunk_size <span class="op">=</span> <span class="fl">100</span>, doc_id <span class="op">=</span> <span class="st">"mobydick"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">chunks</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 2195</span></span>
<span><span class="va">chunks</span><span class="op">[</span><span class="fl">5</span><span class="op">:</span><span class="fl">6</span><span class="op">]</span></span>
<span><span class="co">#&gt; $`mobydick-0005`</span></span>
<span><span class="co">#&gt; [1] "of a poor devil of a sub sub appears to have gone through the long vaticans and street stalls of the earth picking up whatever random allusions to whales he could anyways find in any book whatsoever sacred or profane therefore you must not in every case at least take the higgledy piggledy whale statements however authentic in these extracts for veritable gospel cetology far from it as touching the ancient authors generally as well as the poets here appearing these extracts are solely valuable or entertaining as affording a glancing bird's eye view of what has been promiscuously said"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $`mobydick-0006`</span></span>
<span><span class="co">#&gt; [1] "thought fancied and sung of leviathan by many nations and generations including our own so fare thee well poor devil of a sub sub whose commentator i am thou belongest to that hopeless sallow tribe which no wine of this world will ever warm and for whom even pale sherry would be too rosy strong but with whom one sometimes loves to sit and feel poor devilish too and grow convivial upon tears and say to them bluntly with full eyes and empty glasses and in not altogether unpleasant sadness give it up sub subs for by how much the"</span></span>
<span><span class="fu"><a href="../reference/basic-tokenizers.html">tokenize_words</a></span><span class="op">(</span><span class="va">chunks</span><span class="op">[</span><span class="fl">5</span><span class="op">:</span><span class="fl">6</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt; $`mobydick-0005`</span></span>
<span><span class="co">#&gt;  [1] "of"       "a"        "poor"     "devil"    "of"       "a"       </span></span>
<span><span class="co">#&gt;  [7] "sub"      "sub"      "appears"  "to"       "have"     "gone"    </span></span>
<span><span class="co">#&gt; [13] "through"  "the"      "long"     "vaticans" "and"      "street"  </span></span>
<span><span class="co">#&gt; [19] "stalls"   "of"       "the"      "earth"    "picking"  "up"      </span></span>
<span><span class="co">#&gt; [25] "whatever"</span></span>
<span><span class="co">#&gt;  [ reached getOption("max.print") -- omitted 75 entries ]</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $`mobydick-0006`</span></span>
<span><span class="co">#&gt;  [1] "thought"     "fancied"     "and"         "sung"        "of"         </span></span>
<span><span class="co">#&gt;  [6] "leviathan"   "by"          "many"        "nations"     "and"        </span></span>
<span><span class="co">#&gt; [11] "generations" "including"   "our"         "own"         "so"         </span></span>
<span><span class="co">#&gt; [16] "fare"        "thee"        "well"        "poor"        "devil"      </span></span>
<span><span class="co">#&gt; [21] "of"          "a"           "sub"         "sub"         "whose"      </span></span>
<span><span class="co">#&gt;  [ reached getOption("max.print") -- omitted 75 entries ]</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="counting-words-characters-sentences">Counting words, characters, sentences<a class="anchor" aria-label="anchor" href="#counting-words-characters-sentences"></a>
</h2>
<p>The package also offers functions for counting words, characters, and sentences in a format which works nicely with the rest of the functions.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/word-counting.html">count_words</a></span><span class="op">(</span><span class="va">mobydick</span><span class="op">)</span></span>
<span><span class="co">#&gt; mobydick </span></span>
<span><span class="co">#&gt;   219415</span></span>
<span><span class="fu"><a href="../reference/word-counting.html">count_characters</a></span><span class="op">(</span><span class="va">mobydick</span><span class="op">)</span></span>
<span><span class="co">#&gt; mobydick </span></span>
<span><span class="co">#&gt;  1235185</span></span>
<span><span class="fu"><a href="../reference/word-counting.html">count_sentences</a></span><span class="op">(</span><span class="va">mobydick</span><span class="op">)</span></span>
<span><span class="co">#&gt; mobydick </span></span>
<span><span class="co">#&gt;    29076</span></span></code></pre></div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><!-- begin footer --><div class="footer">
    <div class="container">
        <div class="row start top-4 bottom-8">
            <div class="col-2"> <img id="footerlogo" src="https://ropensci.org/img/icon_short_white.svg">
</div>
            <div class="col-10">
                <div class="row">
                    <div class="col-md-4 col-xs-6">
                        <a href="https://github.com/ropensci" target="_blank" class="external-link"><div class="icon fab fa-github"></div></a>
                        <a href="https://github.com/ropenscilabs" target="_blank" class="external-link"><div class="icon fa fa-flask"></div></a>
                        <a href="https://hachyderm.io/@ropensci" target="_blank" class="external-link"><div class="icon fab fa-mastodon"></div></a>
                        <a href="https://vimeo.com/ropensci" target="_blank" class="external-link"><div class="icon fab fa-vimeo"></div></a>
                    </div>
                </div>
                <div class="row top-4">
                    <div class="col-md-2 col-sm-4">
                        <ul>
<h5 class="bottom-2">About</h5>
                            <li><a href="https://ropensci.org/about" class="external-link">About rOpenSci</a></li>
                            <li><a href="https://ropensci.org/software-review" class="external-link">Software Review</a></li>
                            <li><a href="https://ropensci.org/about#team" class="external-link">Our Team</a></li>
                            <li><a href="https://ropensci.org/careers" class="external-link">Jobs</a></li>
                            <li><a href="https://ropensci.org/donate" class="external-link">Donate</a></li>
                            <li><a href="https://ropensci.org/contact" class="external-link">Contact Us</a></li>
                        </ul>
</div>
                    <div class="col-md-3 col-sm-4">
                        <ul>
<h5 class="bottom-2">Community</h5>
                            <li><a href="https://ropensci.org/community/" class="external-link">Our Community</a></li>
                            <li><a href="https://ropensci.org/commcalls/" class="external-link">Community calls</a></li>
                            <li><a href="https://ropensci.org/events/" class="external-link">Events</a></li>
                            <li><a href="https://discuss.ropensci.org/" class="external-link">Join the Discussion</a></li>
                            <li><a href="https://ropensci.org/code-of-conduct" class="external-link">Code of conduct</a></li>
                        </ul>
</div>
                    <div class="col-md-2 col-sm-4">
                        <ul>
<h5 class="bottom-2">Resources</h5>
                            <li><a href="https://ropensci.org/packages/" class="external-link">Packages</a></li>
                            <li><a href="https://ropensci.org/usecases/" class="external-link">Use Cases</a></li>
                            <li><a href="https://ropensci.org/talks-papers/" class="external-link">Talks &amp; Publications</a></li>
                            <li><a href="https://docs.ropensci.org/" class="external-link">Documentation</a></li>
                            <li><a href="https://ropensci.org/news/" class="external-link">Newsletter</a></li>
                            <li><a href="https://ropensci.org/how-to-cite-ropensci/" class="external-link">Cite rOpenSci</a></li>
                        </ul>
</div>
                    <div class="col-md-4 col-xs-12">
                        <h5 class="bottom-2"></h5>

                        <p>rOpenSci is a fiscally sponsored project of <a href="http://numfocus.org" class="external-link">NumFOCUS</a>.</p>

                    </div>
                </div>
            </div>
        </div>
    </div>
</div>
<!-- / end footer -->


    </footer>
</div>

  

  

  </body>
</html>
